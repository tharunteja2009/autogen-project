# 🧐 Multi-Agent Code Generation and Execution Framework

This project is built using [AutoGen](https://github.com/microsoft/autogen) — a powerful framework to orchestrate multi-agent conversations. The system uses a team of agents to handle **code generation**, **code execution via Docker**, and return the **final output to the user**.

## 🔧 Features

* Multi-agent orchestration using AutoGen
* Code generation powered by LLMs
* Docker-based code execution in a secure environment
* Modular and extensible agent design

## 📁 Project Structure

```
🔹 agents/
│   ├── user_proxy_agent.py         # Handles user input and initiates the task
│   ├── code_generator_agent.py     # Agent responsible for generating code using LLMs
│   └── code_executor_agent.py    # Executes the generated code securely in Docker
🔹 utils/
│   └── docker_utils.py       # Utilities for Docker management and execution
🔹 utils/
│   └── software_development_team.py # intialized with roundrobingroup chat at the moment 
🔹 main.py                   # Main entry point: initializes team and starts interaction
🔹 requirements.txt
🔹 README.md
```

## 🚀 Getting Started

### Prerequisites

* Python 3.9+
* Docker installed and running
* OpenAI or other LLM API key configured (for AutoGen)

### Installation

1. **Clone the repository**

```bash
git clone https://github.com/your-username/multi-agent-codegen.git
cd multi-agent-codegen
```

2. **Create virtual environment (optional)**

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Set environment variables**

Create a `.env` file or export your keys:

```bash
export OPENAI_API_KEY="your-openai-api-key"
```

### Run the Project

```bash
python main.py
```

The agents will initiate a conversation. Provide a programming task, and the system will:

1. Understand the user request
2. Generate the appropriate code
3. Execute the code inside Docker
4. Return the output back to the user

## ⚙️ Customization

* **Add a new agent**: Create a new class extending `autogen.Agent` and register it in `main.py`.
* **Change execution environment**: Modify `docker_utils.py` to customize the container (e.g., language/runtime).
* **Switch LLM providers**: Configure different LLM endpoints in the AutoGen agent config.

## 🧪 Example Use Case

```
User: Write a Python function to calculate the factorial of a number.

System:
✔️ Code generated by CodeGeneratorAgent
✔️ Code executed in Docker
✔️ Output: factorial(5) = 120
```

## 📌 Roadmap

* [ ] Add support for multi-language execution
* [ ] Integrate error recovery in code execution
* [ ] Add logging and conversation history

## 🤝 Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss what you'd like to change.

## 🛡️ License

MIT License

---

**Developed with ❤️ using AutoGen**
