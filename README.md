# ğŸ§ Multi-Agent Code Generation and Execution Framework

This project is built using [AutoGen](https://github.com/microsoft/autogen) â€” a powerful framework to orchestrate multi-agent conversations. The system uses a team of agents to handle **code generation**, **code execution via Docker**, and return the **final output to the user**.

---

## ğŸ”§ Features

- Multi-agent orchestration using AutoGen
- Code generation powered by LLMs
- Docker-based code execution in a secure environment
- Modular and extensible agent design

---

## ğŸ“ Project Structure

```
ğŸ”¹ agents/
â”‚   â”œâ”€â”€ user_proxy_agent.py         # Handles user feedback and approves or rejects code
â”‚   â”œâ”€â”€ code_generator_agent.py     # Agent responsible for generating Python code using LLMs
â”‚   â””â”€â”€ code_executor_agent.py      # Executes the generated code securely in Docker

ğŸ”¹ utils/
â”‚   â””â”€â”€ docker_utils.py             # Utilities for Docker management and execution

ğŸ”¹ teams/
â”‚   â””â”€â”€ software_development_team.py # Round-robin group chat coordination logic

ğŸ”¹ main.py                           # Main entry point: initializes the team and starts the interaction
ğŸ”¹ requirements.txt
ğŸ”¹ README.md
```

---

## ğŸ”„ Agent Workflow

```mermaid
flowchart TD
    A[Code Generator Agent] --> B[Code Executor Agent]
    B --> C[User Proxy Agent]
    C -->|Feedback / Request Fix| A
    C -->|APPROVE| D[Stop Execution]
    A -->|Code Perfect / STOP| D
```

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.9+
- Docker installed and running
- OpenAI or other LLM API key configured (for AutoGen)

### Installation

1. **Clone the repository**

```bash
git clone https://github.com/your-username/multi-agent-codegen.git
cd multi-agent-codegen
```

2. **Create a virtual environment (optional)**

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Set environment variables**

Create a `.env` file or export your keys manually:

```bash
export OPENAI_API_KEY="your-openai-api-key"
```

---

### ğŸƒ Run the Project

```bash
python main.py
```

The agents will initiate a conversation. Provide a programming task, and the system will:

1. Understand the user request
2. Generate the appropriate Python code
3. Execute the code inside Docker
4. Return the output to the user
5. Refine until "APPROVE" or "STOP"

---

## ğŸ§ª Example Use Case

```plaintext
User: Write a Python function to calculate the factorial of a number.

System:
âœ”ï¸ Code generated by CodeGeneratorAgent
âœ”ï¸ Code executed in Docker
âœ”ï¸ Output: factorial(5) = 120
âœ”ï¸ User approves result
```

---

## âš™ï¸ Customization

- **Add a new agent**: Create a new class extending `autogen.Agent` and register it in `main.py`.
- **Change execution environment**: Modify `docker_utils.py` to customize the Docker container.
- **Switch LLM providers**: Configure different LLM endpoints in the AutoGen agent setup.

---

## ğŸ“Œ Roadmap

- [ ] Add support for multi-language code execution
- [ ] Integrate error recovery and retry logic for failed executions
- [ ] Store and visualize full agent conversation history

---

## ğŸ—ƒï¸ Logs

Conversation history will be logged in your OpenAI usage dashboard:

ğŸ‘‰ [https://platform.openai.com/logs](https://platform.openai.com/logs)

---

## ğŸ¤ Contributing

Pull requests are welcome. For major changes, please open an issue first to discuss the proposal.

---

## ğŸ›¡ï¸ License

MIT License

---

**Developed with â¤ï¸ using AutoGen**